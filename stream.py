import streamlit as st
import pandas as pd
import numpy as np
import faiss
import openai
import re
import os
from PIL import Image
from sklearn.model_selection import train_test_split

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ìœ„í—˜ì„±í‰ê°€ ìë™ ìƒì„± ë° ì‚¬ê³  ì˜ˆì¸¡",
    page_icon="ğŸ› ï¸",
    layout="wide"
)

# ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #0D47A1;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .info-text {
        font-size: 1rem;
        color: #424242;
        margin-bottom: 1rem;
    }
    .highlight {
        background-color: #e3f2fd;
        padding: 5px;
        border-radius: 5px;
    }
    .result-box {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 15px;
        margin-top: 10px;
        margin-bottom: 10px;
        border-left: 5px solid #4CAF50;
    }
    .phase-badge {
        background-color: #4CAF50;
        color: white;
        padding: 5px 10px;
        border-radius: 15px;
        font-size: 0.8rem;
        margin-right: 10px;
    }
</style>
""", unsafe_allow_html=True)

# í—¤ë” í‘œì‹œ
st.markdown('<div class="main-header">AI í™œìš© ìœ„í—˜ì„±í‰ê°€ ìë™ ìƒì„± ë° ì‚¬ê³  ì˜ˆì¸¡</div>', unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "index" not in st.session_state:
    st.session_state.index = None
if "embeddings" not in st.session_state:
    st.session_state.embeddings = None
if "retriever_pool_df" not in st.session_state:
    st.session_state.retriever_pool_df = None

# íƒ­ ì„¤ì •
tabs = st.tabs(["ì‹œìŠ¤í…œ ê°œìš”", "ìœ„í—˜ì„± í‰ê°€ (Phase 1)", "ê°œì„ ëŒ€ì±… ìƒì„± (Phase 2)"])

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def determine_grade(value):
    if 16 <= value <= 25:
        return 'A'
    elif 10 <= value <= 15:
        return 'B'
    elif 5 <= value <= 9:
        return 'C'
    elif 3 <= value <= 4:
        return 'D'
    elif 1 <= value <= 2:
        return 'E'
    else:
        return 'ì•Œ ìˆ˜ ì—†ìŒ'

def load_data(selected_dataset_name):
    try:
        df = pd.read_excel(f"{selected_dataset_name}.xlsx")
        if 'ì‚­ì œ Del' in df.columns:
            df = df.drop(['ì‚­ì œ Del'], axis=1)
        df = df.iloc[1:]
        df = df.rename(columns={df.columns[4]: 'ë¹ˆë„', df.columns[5]: 'ê°•ë„'})
        df['T'] = pd.to_numeric(df.iloc[:,4]) * pd.to_numeric(df.iloc[:,5])
        df = df.iloc[:,:7]
        df.rename(
            columns={
                'ì‘ì—…í™œë™ ë° ë‚´ìš©\nWork & Contents':'ì‘ì—…í™œë™ ë° ë‚´ìš©',
                'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥\nHazard & Risk':'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥',
                'í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥\nDamage & Effect':'í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥'
            }, inplace=True)
        df = df.rename(columns={df.columns[6]:'T'})
        df['ë“±ê¸‰'] = df['T'].apply(determine_grade)
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.warning("Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        data = {
            "ì‘ì—…í™œë™ ë° ë‚´ìš©": ["Shoring Installation","In and Out of materials","Transport / Delivery","Survey and Inspection"],
            "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥": ["Fall and collision due to unstable ground","Overturning of transport vehicle","Collision between transport vehicle","Personnel fall while inspecting"],
            "í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥": ["Injury","Equipment damage","Collision injury","Fall injury"],
            "ë¹ˆë„": [3,3,3,2], "ê°•ë„": [2,3,5,3]
        }
        df = pd.DataFrame(data)
        df['T'] = df['ë¹ˆë„'] * df['ê°•ë„']
        df['ë“±ê¸‰'] = df['T'].apply(determine_grade)
        return df

def embed_texts_with_openai(texts, model="text-embedding-3-large", api_key=None):
    if api_key:
        openai.api_key = api_key
    embeddings = []
    progress_bar = st.progress(0)
    total = len(texts)
    for idx, text in enumerate(texts):
        try:
            text = str(text).replace("\n"," ")
            response = openai.Embedding.create(model=model, input=[text])
            embeddings.append(response["data"][0]["embedding"])
        except:
            embeddings.append([0]*1536)
        progress_bar.progress((idx+1)/total)
    return embeddings

def generate_with_gpt(prompt, api_key=None, model="gpt-4o"):
    if api_key:
        openai.api_key = api_key
    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role":"system","content":"ìœ„í—˜ì„± í‰ê°€ ë° ê°œì„ ëŒ€ì±… ìƒì„±ì„ ë•ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
            {"role":"user","content":prompt}
        ],
        temperature=0.0,
        max_tokens=250
    )
    return response['choices'][0]['message']['content'].strip()

# Phase 1: ìœ í•´ìœ„í—˜ìš”ì¸ ì˜ˆì¸¡
def construct_prompt_phase1_for_hazard(retrieved_docs, query_activity):
    """
    retrieved_docs: DataFrame with columns 'content' and 'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥'
    Generates a prompt listing 3 examples and the user query.
    """
    prompt = ""
    # ì•ˆì „í•˜ê²Œ iterrowsë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¬ëŸ¼ëª… ê¸°ì¤€ ì ‘ê·¼
    for i, (_, row) in enumerate(retrieved_docs.iterrows(), 1):
        activity = row['content']
        hazard   = row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']
        # newlineì€ 
ìœ¼ë¡œ ëª…ì‹œ
        prompt += f"ì˜ˆì‹œ {i}: ì…ë ¥: {activity} â†’ {hazard}
"
    # ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬
    prompt += (
        f"ì…ë ¥: {query_activity}
"
        "ìœ„ ì‘ì—…í™œë™ ë° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ í•´ìœ„í—˜ìš”ì¸ì„ ì˜ˆì¸¡í•˜ì„¸ìš”.
"
        "JSONìœ¼ë¡œ ë°˜í™˜: {\"ìœ í•´ìœ„í—˜ìš”ì¸\": \"...\"}
"
    )
    return prompt

def parse_gpt_output_phase1_for_hazard(gpt_output):
    try:
        m = re.search(r'\{.*\}', gpt_output, re.DOTALL)
        return eval(m.group())['ìœ í•´ìœ„í—˜ìš”ì¸'] if m else None
    except:
        return None

# Phase 2: ê°œì„ ëŒ€ì±… ìƒì„±
def compute_rrr(T_before, T_after):
    return ((T_before - T_after) / T_before * 100) if T_before else 0.0

def construct_prompt_phase2(retrieved_docs, activity_text, hazard_text, freq, intensity, T, target_language="Korean"):
    example_section = ""
    for idx, row in enumerate(retrieved_docs.itertuples(),1):
        plan = row._asdict().get('ê°œì„ ëŒ€ì±…') or ''
        example_section += (
            f"Example {idx}:\n"
            f"Activity: {row._asdict()['ì‘ì—…í™œë™ ë° ë‚´ìš©']}\n"
            f"Hazard: {row._asdict()['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}\n"
            f"Plan: {plan}\n\n"
        )
        if idx >= 3: break

    prompt = (
        f"{example_section}"
        "Now here is a new input:\n"
        f"Activity: {activity_text}\n"
        f"Hazard: {hazard_text}\n"
        f"Original Freq: {freq}, Intensity: {intensity}, T: {T}\n\n"
        "ìœ„ JSON í‚¤ë¡œ ê°œì„ ëŒ€ì±… ìƒì„±:\n"
        "{\n"
        "  \"ê°œì„ ëŒ€ì±…\": [...],\n"
        "  \"ê°œì„  í›„ ë¹ˆë„\": NUM,\n"
        "  \"ê°œì„  í›„ ê°•ë„\": NUM,\n"
        "  \"ê°œì„  í›„ T\": NUM,\n"
        "  \"T ê°ì†Œìœ¨\": NUM\n"
        "}\n"
    )
    return prompt


def parse_gpt_output_phase2(gpt_output):
    try:
        m = re.search(r'\{.*\}', gpt_output, re.DOTALL)
        return eval(m.group()) if m else None
    except:
        return None

# ë°ì´í„°ì…‹ ì˜µì…˜
dataset_options = {
    "SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)":"SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)",
    "Civil (í† ëª©)":"Civil (í† ëª©)",
    "Marine (í† ëª©)":"Marine (í† ëª©)",
    "SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)":"SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)",
    "SWRO ì „ê¸°ì‘ì—…í‘œì¤€ (í”ŒëœíŠ¸)":"SWRO ì „ê¸°ì‘ì—…í‘œì¤€ (í”ŒëœíŠ¸)"
}

# ì‹œìŠ¤í…œ ê°œìš” íƒ­
with tabs[0]:
    st.markdown('<div class="sub-header">ì‹œìŠ¤í…œ ê°œìš”</div>', unsafe_allow_html=True)
    st.markdown("LLM ê¸°ë°˜ ìœ„í—˜ì„± í‰ê°€ ë° ê°œì„ ëŒ€ì±… ìë™í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.")

# Phase1 íƒ­
with tabs[1]:
    st.markdown('<div class="sub-header">ìœ„í—˜ì„± í‰ê°€ (Phase 1)</div>', unsafe_allow_html=True)
    api_key = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
    dataset = st.selectbox("ë°ì´í„°ì…‹ ì„ íƒ", list(dataset_options.keys()))
    if st.button("ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì„±"):
        if api_key:
            df = load_data(dataset_options[dataset])
            train_df, _ = train_test_split(df, test_size=0.1, random_state=42)
            retriever = train_df.copy()
            retriever['content'] = retriever['ì‘ì—…í™œë™ ë° ë‚´ìš©']
            emb = embed_texts_with_openai(retriever['content'].tolist(), api_key=api_key)
            index = faiss.IndexFlatL2(len(emb[0]))
            index.add(np.array(emb, dtype='float32'))
            st.session_state.index = index
            st.session_state.retriever_pool_df = retriever
    if st.session_state.index:
        act = st.text_input("ì‘ì—…í™œë™ ë° ë‚´ìš© ì…ë ¥:")
        if st.button("ìœ í•´ìœ„í—˜ìš”ì¸ ì˜ˆì¸¡í•˜ê¸°"):
            emb_q = embed_texts_with_openai([act], api_key=api_key)[0]
            D, I = st.session_state.index.search(np.array([emb_q], dtype='float32'), 3)
            docs = st.session_state.retriever_pool_df.iloc[I[0]]
            prompt = construct_prompt_phase1_for_hazard(docs, act)
            out = generate_with_gpt(prompt, api_key)
            hz = parse_gpt_output_phase1_for_hazard(out)
            st.write("ì˜ˆì¸¡ ìœ í•´ìœ„í—˜ìš”ì¸:", hz)
            st.write("ìœ ì‚¬ ì‚¬ë¡€:")
            for r in docs.itertuples():
                st.write(f"- {r._asdict()['ì‘ì—…í™œë™ ë° ë‚´ìš©']} â†’ {r._asdict()['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}")

# Phase2 íƒ­
with tabs[2]:
    st.markdown('<div class="sub-header">ê°œì„ ëŒ€ì±… ìƒì„± (Phase 2)</div>', unsafe_allow_html=True)
    api_key2 = st.text_input("OpenAI API í‚¤:", type="password", key="api_key2")
    lang = st.selectbox("ì–¸ì–´ ì„ íƒ:", ["Korean","English","Chinese"])
    method = st.radio("ì…ë ¥ ë°©ì‹:", ["Phase1 ê²°ê³¼","ì§ì ‘ ì…ë ¥"])
    if method == "Phase1 ê²°ê³¼" and 'index' in st.session_state and hasattr(st.session_state, 'retriever_pool_df'):
        # Phase1 ê²°ê³¼ ì‚¬ìš©
        pass
    else:
        a = st.text_input("ì‘ì—…í™œë™:")
        h = st.text_input("ìœ í•´ìœ„í—˜ìš”ì¸:")
        f = st.slider("ë¹ˆë„",1,5,3)
        i = st.slider("ê°•ë„",1,5,3)
        T0 = f*i
        if st.button("ê°œì„ ëŒ€ì±… ìƒì„±"):
            emb_q2 = embed_texts_with_openai([f"{a} {h}"], api_key=api_key2)[0]
            D2, I2 = st.session_state.index.search(np.array([emb_q2], dtype='float32'), 3)
            docs2 = st.session_state.retriever_pool_df.iloc[I2[0]]
            prompt2 = construct_prompt_phase2(docs2, a, h, f, i, T0, lang)
            out2 = generate_with_gpt(prompt2, api_key2)
            res2 = parse_gpt_output_phase2(out2)
            st.write(res2)

# í‘¸í„°
st.markdown('<hr>', unsafe_allow_html=True)
st.markdown('<div style="display:flex;justify-content:space-between;align-items:center;">', unsafe_allow_html=True)
col1, col2 = st.columns(2)
with col1:
    if os.path.exists("cau.png"): st.image(Image.open("cau.png"), width=150)
with col2:
    if os.path.exists("doosan.png"): st.image(Image.open("doosan.png"), width=180)
st.markdown('</div>', unsafe_allow_html=True)
